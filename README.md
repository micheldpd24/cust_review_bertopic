# **BERTopic Customer Reviews Topic Modeling**

## **Overview**
This project uses **BERTopic**, a powerful topic modeling library, to analyze customer reviews and extract meaningful topics. The pipeline is designed to be modular, scalable, and easy to integrate into an ETL (Extract, Transform, Load) pipeline. It includes:

- **Data Loading**: Preprocessing raw customer review data.
- **Topic Modeling**: Training a BERTopic model to identify topics in the reviews.
- **Evaluation**: Calculating coherence scores and topic diversity metrics to evaluate model performance.
- **Visualization**: Providing an interactive dashboard to explore topics, their distributions, and related documents.
- **Docker Integration**: Packaging the application into a Docker container for seamless deployment in production environments.

---

## **Features**
1. **BERTopic Model**:
   - Utilizes transformers for embeddings, UMAP for dimensionality reduction, and HDBSCAN for clustering.
   - Configurable parameters via a YAML configuration file.

2. **Interactive Dashboard**:
   - Built using **Dash** and **Plotly** for visualizing topics, topic distributions, and sample documents.
   - Includes tabs for:
     - Topic overview
     - Document map (2D visualization of topics)
     - Topic hierarchy
     - Top terms per topic
     - Topic distribution

3. **Model Evaluation**:
   - Computes coherence scores using Gensim's CoherenceModel.
   - Calculates topic diversity to measure the uniqueness of topics.

4. **Docker Support**:
   - The application is containerized for easy deployment at the end of an ETL pipeline.

---

## **Project Structure**
The project is organized as follows:

```
â”œâ”€â”€ main.py                  # Main script to run the pipeline
â”œâ”€â”€ Dockerfile               # Docker configuration for containerization
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ config.yaml              # Configuration file for pipeline parameters
â”œâ”€â”€ assets/                  # Dashboard screenshots
â”œâ”€â”€ data/                    # Directory for input/output data
â”‚   â”œâ”€â”€ full/                # Raw customer reviews (zip file of customer reviews csv file)
â”‚   â””â”€â”€ results/             # Output directory for model artifacts
â””â”€â”€ README.md                # Project documentation
```

---

## **Dashboard Screenshots**
Below are some screenshots of the interactive dashboard generated by the pipeline. These visuals provide insights into the topics extracted from customer reviews and their relationships.

### **0. Dashboard Overview**
Overall view of the dashboard layout
![Dashboard layout](assets/dashboard.png)

### **1. Topic Overview**
This tab provides a high-level summary of the identified topics, including their sizes and names.

![Topic Overview](assets/topic_overview.png)

### **2. Document Map**
A 2D visualization of the topics and their associated documents. Each point represents a document, colored by its assigned topic.

![Document Map](assets/document_map.png)

### **3. Topic Hierarchy**
A hierarchical representation of the topics, showing how they are grouped and related to each other.

![Topic Hierarchy](assets/topic_hierarchy.png)

### **4. Top Terms Per Topic**
A bar chart displaying the top terms for each topic, highlighting the most representative words.

![Top Terms](assets/top_terms.png)

### **5. Topic Distribution**
A distribution plot showing the probability distribution of topics across the dataset.

![Topic Distribution](assets/topic_distribution.png)

---

## **Configuration**
The pipeline is configured using a YAML file (`config.yaml`). Below is an example configuration:

```yaml
# config.yaml
# -----------
data:
  input_filepath: "/data/full/full_reviews.csv"     # Path to the input CSV file
  review_column: "review"                           # Column containing review texts
  sample_size: null                                 # Optional: Number of reviews to sample

model:
  transformer_name: "all-MiniLM-L6-v2"
  language: "french"
  min_topic_size: 10
  nr_topics: "auto"
  umap:
    n_neighbors: 15
    n_components: 5
    min_dist: 0.0
    metric: "cosine"
  hdbscan:
    min_cluster_size: 15
    metric: "euclidean"
    cluster_selection_method: "eom"
    prediction_data: true
  vectorizer:
    stop_words: None
    ngram_range: [1, 2]

evaluation:
  coherence_metrics:                     # Coherence metrics to calculate
    - "c_v"
    - "u_mass"
    - "c_npmi"
  sample_size: 2900                     # For coherence calculation

output:
  save_model: true                      # Whether to save the trained model
  output_dir: "/data/output/models"     # Directory to save model outputs
  dashboard_port: 8050                  # Port for the Dash dashboard
```

---

## **Usage**

### **1. Prerequisites**
- Python 3.8 or higher
- Docker (for containerization)

Install the required dependencies:
```bash
pip install -r requirements.txt
```

### **2. Running the Pipeline**
To run the pipeline locally, execute the following command:
```bash
python main.py --config config.yaml
```

This will:
1. Load and preprocess the customer reviews.
2. Train the BERTopic model.
3. Evaluate the model using coherence and diversity metrics.
4. Save the trained model and outputs to the specified directory.
5. Launch the interactive Dash dashboard.

### **3. Accessing the Dashboard**
Once the pipeline is running, the dashboard will be accessible at:
```
http://localhost:8050
```

### **4. Docker Deployment**
To deploy the application using Docker:

#### **Step 0 : Unzip the Reviews data file**
```bash
unzip data/full/full_reviews.zip -d data/full/
```

#### **Step 1: Build the Docker Image**
```bash
docker build -t bertopic-container .
```

#### **Step 2: Run the Container**
```bash
docker run -p 8051:8050 \
           -v "$PWD/data/full:/data/full" \
           -v "$PWD/data/output:/data/output" \
           -v "$PWD:/app" \
           bertopic-container
```

Access the dashboard at:
```
http://localhost:8051
```

---

## **Evaluation Metrics**
The pipeline evaluates the topic model using the following metrics:
1. **Coherence Scores**:
   - Measures the interpretability of topics.
   - Supported metrics: `c_v`, `u_mass`, `c_uci`, `c_npmi`.

2. **Topic Diversity**:
   - Measures the uniqueness of topics by calculating the ratio of unique words to total words across all topics.

---
## **References**
[ Maarten Grootendorst. Leveraging BERT and c-TF-IDF to create easily interpretable topics](https://github.com/MaartenGr/BERTopic)

---

## **License**
This project is licensed under the **MIT License**. See the `LICENSE` file for details.

---

Feel free to reach out with any questions or suggestions! ðŸš€


